{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ec9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import derinet.lexicon as dlex\n",
    "import os\n",
    "lexicon = dlex.Lexicon()\n",
    "current_dir = os.getcwd()  # aktualni adresar\n",
    "file_path = os.path.join(current_dir, \"./derinet-2-3.tsv\")  #sestaveni cesty\n",
    "lexicon.load(file_path)\n",
    "\n",
    "all_lemmas = {lex.lemma for lex in lexicon.iter_lexemes()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42efe812",
   "metadata": {},
   "source": [
    "    test 8: kontrola přiřazení číslovek podle koncovky (-tý, -tero, -terý)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2135aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvorba_predku():\n",
    "    predci = set()\n",
    "    for lex in lexicon.iter_lexemes(): \n",
    "        if lex.pos == \"NUM\":\n",
    "            predci.add(lex.lemma)\n",
    "    return predci \n",
    "\n",
    "def hledani_predku(predci, dite):\n",
    "    mozni = set()\n",
    "    for lex in predci:\n",
    "        if lex in dite and lex != dite: \n",
    "            mozni.add(lex)\n",
    "    \n",
    "    konecny = set()\n",
    "    #tohle to míří na to, abych tam neměl sto a stodva zároveň\n",
    "    for i in mozni:\n",
    "        for j in mozni:\n",
    "            if i in j and i != j:\n",
    "                konecny.add(i)\n",
    "    \n",
    "    return mozni.difference(konecny)\n",
    "\n",
    "def vypisovani(existuji, neexistuji):\n",
    "    with open(\"test8.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"ČÍSLOVKY KONČÍCÍ NA 'ERO', 'ERÝ', 'KRÁT', 'ISTÝ', KTERÉ JSOU BEZ RODIČE \\n\")\n",
    "        f.write(\"ČÍSLOVKY S NALEZENÝMI PŘEDKY: \\n\")\n",
    "\n",
    "        f.write(\"PŘÍKLAD TISKU: \\n\")\n",
    "        f.write(\"číslovka \\n\")\n",
    "        f.write(f\"  předek\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        for pod, cisla in sorted(existuji, key=lambda x: len(x[1]), reverse=False):\n",
    "            f.write(f\"{pod}\\n\")\n",
    "            for i in cisla:\n",
    "                f.write(f\"  {i}\\n\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"ČÍSLOVKY, PRO KTERÉ NEBYL NALEZEN PŘEDEK: \\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in neexistuji:\n",
    "            f.write(f\"{i} \\n\")\n",
    "\n",
    "#mireno na slova jako desatero, devátý,\n",
    "\n",
    "seznam = []\n",
    "bez = []\n",
    "predci = tvorba_predku()\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.pos == \"NUM\" and lexeme.lemma.endswith((\"tero\", \"terý\", \"krát\", \"istý\", \"erý\", \"ero\")) :\n",
    "        if lexeme.all_parents == []:\n",
    "            moznosti = []\n",
    "            hotovo = False\n",
    "            rodic = None\n",
    "\n",
    "            if lexeme.lemma.endswith(\"krát\"):\n",
    "                rodic = lexeme.lemma[:-4]\n",
    "            elif lexeme.lemma.endswith(\"istý\"):\n",
    "                moznosti.append(\"sto\")\n",
    "                rodic = lexeme.lemma[:-4]\n",
    "            elif lexeme.lemma.endswith((\"erý\", \"ero\")):\n",
    "                rodic = lexeme.lemma[:-3]\n",
    "            else:\n",
    "                print(lexeme.lemma)\n",
    "\n",
    "            #když stačí uříznout jenom konec\n",
    "            if rodic is not None:\n",
    "                if rodic in all_lemmas:\n",
    "                    moznosti.append(rodic)\n",
    "                    hotovo = True\n",
    "            \n",
    "            if not hotovo:  \n",
    "                dalsi = None      \n",
    "                if rodic.endswith((\"dvacát\", \"čtyřicát\", \"třicat\")):\n",
    "                    dalsi = rodic[:-2] + \"e\" + rodic[-1]\n",
    "                elif rodic.endswith(\"devat\"):\n",
    "                    dalsi = rodic[:-2] + \"ě\" + rodic[-1]\n",
    "                elif rodic == \"desat\":\n",
    "                    dalsi = \"deset\"\n",
    "                elif rodic.endswith(\"desat\"):\n",
    "                    dalsi = rodic[:-2] + \"á\" + rodic[-1]\n",
    "                elif rodic.startswith(\"dvou\"):\n",
    "                    dalsi = rodic[4:]\n",
    "                    moznosti.append(\"dva\")\n",
    "                elif rodic.startswith(\"tří\"):\n",
    "                    dalsi = rodic[3:]\n",
    "                    moznosti.append(\"tři\")\n",
    "                elif lexeme.lemma.endswith(\"krát\"):\n",
    "                    dalsi = lexeme.lemma[:-3]\n",
    "                elif rodic == \"st\":\n",
    "                    moznosti.append(\"sto\")\n",
    "                    hotovo = True\n",
    "\n",
    "                if dalsi is not None:\n",
    "                    if dalsi in all_lemmas:\n",
    "                        moznosti.append(dalsi)\n",
    "                        hotovo = True\n",
    "                    else:\n",
    "                        rodic = dalsi\n",
    "                \n",
    "                if not hotovo:\n",
    "                    mozni_rodice = list(hledani_predku(predci, rodic))\n",
    "                    if mozni_rodice != []:\n",
    "                        moznosti_pom = moznosti + mozni_rodice\n",
    "                        moznosti = moznosti_pom\n",
    "                        hotovo = True\n",
    "\n",
    "                    else:\n",
    "                        bez.append(lexeme.lemma)\n",
    "            \n",
    "            if moznosti != []:\n",
    "                seznam.append((lexeme.lemma, moznosti))\n",
    "             \n",
    "                    \n",
    "vypisovani(seznam, bez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17420d38",
   "metadata": {},
   "source": [
    "test 9: když podstatné jméno ženského rodu končí na 'ka', tak je to odvozené od mužského (ne všechny, ale spoustu z nich -> asistentka x matka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc97ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha\n"
     ]
    }
   ],
   "source": [
    "def nejlepsi(kandidati):\n",
    "    hodnota = 0\n",
    "    nejvyssi = None \n",
    "    for i in kandidati:\n",
    "        #ještě bych sem mohla přidat kontrolu, že je to rodu mužského, ale to nevím, jestli by zvládl derinet\n",
    "        #jestli bych se nepřipravil o to slovo\n",
    "        if i != None:\n",
    "            slovo = lexicon.get_lexemes(i)[0]\n",
    "            if slovo.misc['corpus_stats'] and slovo.misc['corpus_stats']['relative_frequency'] > hodnota:\n",
    "                nejvyssi = slovo.lemma\n",
    "                hodnota = slovo.misc['corpus_stats']['relative_frequency']    \n",
    "\n",
    "    return nejvyssi \n",
    "\n",
    "def test(nove):\n",
    "    kandidati = set()\n",
    "    for i in \"aeioyu\":\n",
    "        if nove + i in all_lemmas:\n",
    "            slovicko = nove + i\n",
    "            if slovicko in all_lemmas:\n",
    "                kandidati.add(slovicko)\n",
    "    return kandidati\n",
    "\n",
    "def mozny_predek(predchudce):\n",
    "    if predchudce in all_lemmas:\n",
    "        return predchudce\n",
    "    else:\n",
    "        if predchudce[-1] not in \"aáeěiíoóuůúyý\":\n",
    "            dalsi = test(predchudce)\n",
    "            if len(dalsi) > 1:\n",
    "                return nejlepsi(dalsi)\n",
    "            elif len(dalsi) == 1:\n",
    "                return dalsi.pop()\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "def vytisknout(seznam, bez):\n",
    "    with open(\"test9.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"PODSTATNÁ JMÉNA ŽENSKÉHO RODU KONČÍCÍ NA SPECIÁLNÍ PŘÍPADY 'KA' A JSOU BEZ PŘEDKA \\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"PODSTATNÁ JMÉNA, KE KTERÝM BYL NALEZEN PŘEDEK \\n\")\n",
    "        f.write(f\"{'PODSTATNÉ JMÉNO'.ljust(20)}{'PŘEDEK'.ljust(20)}\\n\")\n",
    "        for i in seznam:\n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"PODSTATNÁ JMÉNA, PRO NĚŽ NEBYL NALEZEN PŘEDCHŮDCE\\n\")\n",
    "        for i in bez:\n",
    "            f.write(f\"{i} \\n\")\n",
    "\n",
    "\n",
    "\n",
    "seznam = []\n",
    "bez = []\n",
    "\n",
    "def hledani_predka(predek, dite):\n",
    "    kandidati = {lemma for lemma in all_lemmas if predek in lemma and len(predek) < len(lemma) and lemma != dite and len(dite) > len(lemma)}\n",
    "    print(\"ha\")\n",
    "    vysledny = nejlepsi(kandidati)\n",
    "    return vysledny\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.pos == \"NOUN\" and lexeme.lemma.endswith(\"ka\"):\n",
    "        if lexeme.all_parents == []:\n",
    "            if 'Gender' in lexeme.feats and lexeme.feats['Gender'] == 'Fem':\n",
    "                predchudce = lexeme.lemma[:-2]\n",
    "                hotovo = False\n",
    "                #veci jako profesorka a profesor\n",
    "                #ale ne veci jako matka a mat\n",
    "                if predchudce in all_lemmas:\n",
    "                    slovo = lexicon.get_lexemes(predchudce)[0]\n",
    "                    casto_pred = slovo.misc['corpus_stats']['absolute_count']\n",
    "                    casto_po = lexeme.misc['corpus_stats']['absolute_count']\n",
    "\n",
    "                    if casto_po < casto_pred:\n",
    "                        hotovo = True\n",
    "                        seznam.append((lexeme.lemma, slovo.lemma))\n",
    "                \n",
    "                if not hotovo:\n",
    "\n",
    "                    if lexeme.lemma.endswith((\"vka\", \"čka\", \"nka\")):\n",
    "                        predchudce = lexeme.lemma[:-4]\n",
    "                        vysledek = mozny_predek(predchudce)\n",
    "                        if vysledek is not None:\n",
    "                            seznam.append((lexeme.lemma, predchudce))\n",
    "                            hotovo = True\n",
    "\n",
    "                        else:\n",
    "                            predchudce = lexeme.lemma[:-2]\n",
    "                            vysledek = mozny_predek(predchudce)\n",
    "                            if vysledek is not None:\n",
    "                                seznam.append((lexeme.lemma, slovo.lemma))\n",
    "                                hotovo = True\n",
    "                        \n",
    "                        if not hotovo:\n",
    "                            predchudce = lexeme.lemma[:-4]\n",
    "                            cil = hledani_predka(predchudce, lexeme.lemma)\n",
    "                            if cil is not None:\n",
    "                                seznam.append((lexeme.lemma, cil))\n",
    "                                hotovo = True\n",
    "\n",
    "                        if not hotovo:\n",
    "                            bez.append(lexeme.lemma)\n",
    "                    \n",
    "\n",
    "                    #pedagožka a pedagog\n",
    "                    elif lexeme.lemma.endswith(\"žka\"):\n",
    "                        predchudce = predchudce + \"g\"\n",
    "\n",
    "                        if predchudce in all_lemmas:\n",
    "                            seznam.append((lexeme.lemma, predchudce))\n",
    "                        else:\n",
    "                            bez.append(lexeme.lemma)\n",
    "                        \n",
    "                    else: #teď pořešit skandinavistka a skandinavista\n",
    "                        vysledek = mozny_predek(predchudce)\n",
    "                        if vysledek is not None:\n",
    "                            seznam.append((lexeme.lemma, predchudce))\n",
    "    \n",
    "vytisknout(seznam, bez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3ef72",
   "metadata": {},
   "source": [
    "test 10: podstatné jméno končící na 'ost' by mělo být k něčemu připojeno (jasnost, lenost, prázdnost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49686c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hledani(slovo):\n",
    "    rodic = slovo + 'ý'\n",
    "    dalsi = slovo + 'í'\n",
    "\n",
    "    if rodic in all_lemmas:\n",
    "        return rodic\n",
    "    elif dalsi in all_lemmas:\n",
    "        return dalsi\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def tisknuti(seznam, osamocen):\n",
    "    with open(\"test10.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"PODSTATNÁ JMÉNA KONČÍCÍ NA 'OST' A JSOU BEZ PŘEDKA \\n\")\n",
    "        f.write(\"PODSTATNÉ JMÉNO A K NĚMU NALEZENÝ PŘEDEK\\n\")\n",
    "        \n",
    "        f.write(f\"{'PODSTATNÉ JMÉNO'.ljust(20)}{'PŘEDEK'.ljust(20)}\\n\")\n",
    "        for i in seznam:\n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "        f.write(\"PODSTATNÁ JMÉNA, PRO NĚŽ NEBYL NALEZEN PŘEDCHŮDCE\\n\")\n",
    "        f.write(\"SEŘAZENO PODLE ABSOLUTNÍHO POČTU Z lexeme.misc \\n\")\n",
    "        for slovo, predek, vzdalenost in sorted(osamocen, key=lambda x: x[1]):\n",
    "            f.write(f\"{slovo.ljust(20)}{predek.ljust(20)}{str(vzdalenost).ljust(20)}\\n\")\n",
    "        \n",
    "        \n",
    "    \n",
    "seznam = []\n",
    "bez = []\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.lemma.endswith(\"ost\") and lexeme.all_parents == []:\n",
    "        if len(lexeme.lemma[:-3]) > 3:\n",
    "        #nejdřív se podíváme, jestli má rodiče, pokud ne, tak je to problém \n",
    "            predchudce = lexeme.lemma[:-3]\n",
    "            vysledek = hledani(predchudce)\n",
    "\n",
    "            if vysledek is not None:\n",
    "                seznam.append((lexeme.lemma, vysledek))\n",
    "            else:\n",
    "                predchudce = lexeme.lemma[:-4]\n",
    "                vysledek = hledani(predchudce)\n",
    "\n",
    "                if vysledek is not None: \n",
    "                    seznam.append((lexeme.lemma, vysledek))\n",
    "                else:\n",
    "                    hodnota = lexeme.misc.get(\"corpus_stats\", {}).get(\"absolute_count\", 0)\n",
    "                    bez.append((lexeme.lemma, hodnota))\n",
    "\n",
    "tisknuti(seznam, bez)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df86cc91",
   "metadata": {},
   "source": [
    "test 11: stejně dlouhá slova, ale jiný začátek slova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff130ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternativy(otec, syn):\n",
    "    if syn == \"ú\" + otec[2:] or syn == \"o\" + otec[2:]:\n",
    "        return True\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def levenhstein(prvni, druhy):\n",
    "    n = len(prvni)\n",
    "    m = len(druhy)\n",
    "    tabulka = [[0] * (m + 2) for _ in range(n + 2)]\n",
    "    for i in range(1, n+ 2):\n",
    "        tabulka[i][m+1] = n - i + 1\n",
    "    for j in range(1, m + 2):\n",
    "        tabulka[n+ 1][j] = m - j + 1\n",
    "    for i in range(n, 0, -1):\n",
    "        for j in range(m, 0, -1):\n",
    "            delta = 1\n",
    "            if prvni[i - 1] == druhy[j-1]:\n",
    "                delta = 0\n",
    "            tabulka[i][j] = min(delta + tabulka[i + 1][j + 1], 1 + tabulka[i + 1][j], 1 + tabulka[i][j + 1])\n",
    "\n",
    "    return tabulka[1][1]\n",
    "\n",
    "def tisk(resitelne, neresitelne):\n",
    "    with open(\"test11.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"SLOVA, KTERÁ JSOU PODOBNĚ KRÁTKÁ JAKO JEJICH PŘEDEK, ALE ZAČÍNAJÍ NA JINÉ PÍSMENO \\n\")\n",
    "        f.write(\"SEZNAM TĚCH, KTERÉ BY MĚLY BÝT PROHOZENÉ, TEDY RODIČ BY MĚL BÝT POD SYNEM\\n\")\n",
    "        f.write(f\"{'PŮVODNÍ SLOVO'.ljust(20)}{'PŮVODNÍ PŘEDEK'.ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in resitelne: \n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"SEZNAM TĚCH, KTERÉ SPLNILY KRITÉRIA, SEŘAZENY PODLE LEVENHSTEINOVY VZDÁLENOSTI \\n\")\n",
    "        f.write(f\"{'PŮVODNÍ SLOVO'.ljust(20)}{'PŮVODNÍ PŘEDEK'.ljust(20)}{'VZDÁLENOST'.ljust(20)}\\n\")\n",
    "        for i in  sorted(neresitelne, key=lambda x: x[2], reverse=True):\n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}{str(i[2]).ljust(20)}\\n\")\n",
    "    \n",
    "            \n",
    "seznam = []\n",
    "mozne = []\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    for i in lexeme.all_parents:\n",
    "        if len(lexeme.lemma) < len(i.lemma) + 2 and lexeme.lemma[0] != i.lemma[0]:\n",
    "            #pojistit rozdily:\n",
    "            if lexeme.lemma[0].lower() == i.lemma[0].lower(): #čáslavský x Čáslav\n",
    "                continue\n",
    "            elif i.lemma.startswith(\"-\"):\n",
    "                continue\n",
    "            elif len(lexeme.lemma) < 7 and levenhstein(lexeme.lemma, i.lemma) < 2:\n",
    "                continue\n",
    "            elif len(lexeme.lemma) > 6 and levenhstein(lexeme.lemma, i.lemma) < 3:\n",
    "                continue\n",
    "            elif \"apgrejd\" in lexeme.lemma:\n",
    "                if \"upgrade\" + lexeme.lemma[7:] == i.lemma:\n",
    "                    continue  \n",
    "            else:\n",
    "                reseni = alternativy(lexeme.lemma, i.lemma)\n",
    "                if reseni is None:\n",
    "                    seznam.append((lexeme.lemma, i.lemma, levenhstein(lexeme.lemma, i.lemma)))\n",
    "                else:\n",
    "                    mozne.append((lexeme.lemma, i.lemma))\n",
    "\n",
    "tisk(mozne, seznam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757ec82",
   "metadata": {},
   "source": [
    "test 12: test na slova končící na 'á'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seznam = []\n",
    "bez = []\n",
    "\n",
    "def tisk(seznam, bez):   \n",
    "    with open(\"test12.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"SLOVA KONČÍCÍ NA 'Á, KTERÁ NEJSOU K NIČEMU PŘIPOJENA\")\n",
    "        f.write(\"SEZNAM TĚCH, KE KTERÝM BYL NALEZEN POTENCIÁLNÍ PŘEDEK\\n\")\n",
    "        f.write(f\"{'NALEZENÉ SLOVO'.ljust(20)}{'MOŽNÝ PŘEDEK'.ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in seznam: \n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"SEZNAM TĚCH, KE KTERÝM PŘEDEK NEBYL NALEZEN \\n\")\n",
    "        f.write(\"NALEZENÉ SLOVO \\n\")\n",
    "        for i in bez:\n",
    "            f.write(f\"{i}\\n\")\n",
    "        \n",
    "all_lemmas1 = {lemma.lower() for lemma in all_lemmas}\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.lemma[-1] in \"á\":\n",
    "        if lexeme.all_parents == [] and (len(lexeme.lemma) > 3 or lexeme.lemma[0].isupper()):\n",
    "            rodic = \"\"\n",
    "            dalsi = \"\"\n",
    "            if lexeme.lemma.endswith(\"ová\"): #and lexeme.lemma != \"Nová\":\n",
    "                if lexeme.lemma[0].isupper():\n",
    "                    rodic = lexeme.lemma[:-3]\n",
    "                    if rodic[-2] not in \"aáeěiíoóuůúyý\":\n",
    "                        pomoc = rodic[:-1] + \"e\" + rodic[-1]\n",
    "                        dalsi = pomoc\n",
    "                else:\n",
    "                    rodic = lexeme.lemma[:-1] + \"ý\" \n",
    "\n",
    "            elif lexeme.lemma.endswith(\"ická\"):\n",
    "                rodic = lexeme.lemma[:-2] + \"e\"\n",
    "            else:\n",
    "                rodic = lexeme.lemma[:-1].lower()\n",
    "                rodic = rodic + \"ý\"\n",
    "\n",
    "            if rodic in all_lemmas:\n",
    "                seznam.append((lexeme.lemma, rodic))\n",
    "            elif dalsi in all_lemmas:\n",
    "                seznam.append((lexeme.lemma, dalsi))\n",
    "\n",
    "            else:\n",
    "                if lexeme.lemma.endswith(\"ová\"):\n",
    "                    if rodic + \"a\" in all_lemmas:\n",
    "                        seznam.append((lexeme.lemma, rodic + \"a\"))\n",
    "                    else:\n",
    "                        rodic = rodic.lower()\n",
    "                        if rodic in all_lemmas1:\n",
    "                            seznam.append((lexeme.lemma, rodic))\n",
    "                        elif dalsi in all_lemmas1:\n",
    "                            seznam.append((lexeme.lemma, dalsi))\n",
    "                        else:\n",
    "                            if lexeme.lemma.endswith(\"ová\"):\n",
    "                                if rodic + \"a\" in all_lemmas1:\n",
    "                                    seznam.append((lexeme.lemma, rodic + \"a\"))\n",
    "                                else:\n",
    "                                    bez.append(lexeme.lemma)\n",
    "tisk(seznam, bez)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4365757f",
   "metadata": {},
   "source": [
    "test 15: když geografický pojem začínající velkým písmenem má potomka s malým písmenem (Absurdistán -> absurdistán)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9b752f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#absurdistán by měl být odvozen od Absurdistánu?? nebo nějak naopak \n",
    "def tisk(seznam):\n",
    "    with open(\"test15.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"GEOGRAFICKÉ POJMY, KTERÉ MAJÍ IDENTICKÉ SLOVO ZAČÍNAJÍCÍ MALÝM PÍSMENEM A NEJSOU K SOBĚ PŘIPOJENI \\n\")\n",
    "        f.write(f\"{'GEOGRAFICKÝ POJEM'.ljust(20)}{'ODVOZENÉ SLOVO'.ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in seznam: \n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "\n",
    "seznam = []\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if 'NameType' in lexeme.feats and lexeme.feats['NameType'] == 'Geo' and lexeme.lemma[0].isupper():\n",
    "        tvar = lexeme.lemma.lower()\n",
    "        if tvar in all_lemmas:\n",
    "            slovo = lexicon.get_lexemes(tvar)[0]\n",
    "            if lexeme not in slovo.all_parents and slovo not in lexeme.all_parents:\n",
    "                seznam.append((lexeme.lemma, slovo.lemma))\n",
    "                \n",
    "\n",
    "tisk(seznam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46759b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masochizmus\n",
      "ha\n"
     ]
    }
   ],
   "source": [
    "pred, po = \"\", \"\"\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.lemma == \"masochista\":\n",
    "        for i in lexeme.all_parents:\n",
    "            print(i.lemma)\n",
    "        print(\"ha\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac68b49",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79fe3839",
   "metadata": {},
   "source": [
    "test 16: když je dítě kratší než rodič (tohle je test kvůli dvěma slovům)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tisk(seznam):\n",
    "    with open(\"test16.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "        f.write(\"SLOVA, JEJICHŽ RODIČE JSOU KRATŠÍ NEŽ ONY SAMY\\n\")\n",
    "        f.write(\"SEŘAZENO PODLE LEVENHSTEINOVY VZDÁLENOSTI \\n\")\n",
    "        f.write(\"\\n\")\n",
    "        f.write(f\"{'ZKOUMANÉ SLOVO'.ljust(20)}{'RODIČ'.ljust(20)}{'VZDÁLENOST'.ljust(20)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in sorted(seznam,  key=lambda x: x[2], reverse=True): \n",
    "            f.write(f\"{i[0].ljust(20)}{i[1].ljust(20)}{str(i[2]).ljust(20)}\\n\")\n",
    "\n",
    "seznam = []\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    for i in lexeme.all_parents:\n",
    "        if len(i.lemma) > len(lexeme.lemma) + 2 and lexeme.pos == i.pos:\n",
    "            casto_i = i.misc[\"corpus_stats\"][\"absolute_count\"]\n",
    "            casto_lemma = lexeme.misc[\"corpus_stats\"][\"absolute_count\"]\n",
    "\n",
    "            if casto_i < casto_lemma:\n",
    "                if lexeme.lemma.endswith((\"ismus\", \"izmus\")) and levenhstein(lexeme.lemma[:-5], i.lemma) < 2:\n",
    "                    continue\n",
    "                elif lexeme.lemma.endswith((\"ika\")) and levenhstein(lexeme.lemma[:-3], i.lemma) < 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    seznam.append((lexeme.lemma, i.lemma, levenhstein(lexeme.lemma, i.lemma)))\n",
    "\n",
    "tisk(seznam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7908020f",
   "metadata": {},
   "source": [
    "test 17: aforizmus -> aforista a aforismus                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "50bd85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tisk(ismy, jenom_jeden):\n",
    "    with open(\"test17.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre¨\n",
    "        f.write(\"TEST ZABÝVAJÍCÍ SE VZTAHY MEZI -IZMUS, -ISMUS A -ISTICKÝ\\n\")\n",
    "        f.write(\"SEZNAM SLOV, KTERÉ KONČÍ NA 'IZMUS', ALE NEJSOU PŘIPOJENA K VERZI 'ISMUS'\\n\")\n",
    "        f.write(f\"{'-IZMUS'.ljust(30)}{'-ISMUS'.ljust(30)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in ismy: \n",
    "            f.write(f\"{i[0].ljust(30)}{i[1].ljust(30)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "        f.write(\"SEZNAM SLOV KONČÍCÍ NA 'ISTICKÝ', KTERÁ JSOU PŘIPOJENA NA 'IZMUS', ALE NE 'ISMUS\\n\")\n",
    "        f.write(f\"{'-ISTICKÝ'.ljust(30)}{'ŠPATNĚ: -IZMUS'.ljust(30)}{'SPRÁVNĚ: -ISMUS'.ljust(30)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        for i in jenom_jeden: \n",
    "            f.write(f\"{i[1].ljust(30)}{i[0].ljust(30)}{i[2].ljust(30)}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    \n",
    "seznam = [] #když masochizmus není příbuzný masochismu\n",
    "nespojeno = [] #nespojeno - nacionalista je pouze pod nacionalizmem a ne pod nacionalismem\n",
    "#spojeno_blbe - pripojen k obema (nacionalista jak pod nacionalizmus tak nacionalismus)\n",
    "\n",
    "all_lemmas = {lex.lemma for lex in lexicon.iter_lexemes()}\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if lexeme.lemma.endswith(\"izmus\"): #podívám se, jestli má předka to slovo se 's'\n",
    "        rodic = lexeme.lemma[:-4] + \"s\" + lexeme.lemma[-3:]\n",
    "        if lexeme.all_parents == []:\n",
    "            if rodic in all_lemmas:\n",
    "                seznam.append((lexeme.lemma, rodic))\n",
    "                #f.write(f\"????{lexeme.lemma} a {rodic} by měly být příbuzní \\n\")\n",
    "        \n",
    "        #pak se podívám do všech dětí, jestli tam nemá 'ista', i když by tam být neměl, protože to je od jiného slova\n",
    "        deti = lexeme.children \n",
    "        for d in deti:\n",
    "            if d.lemma.endswith(\"ista\"):\n",
    "                if rodic in all_lemmas: \n",
    "                    #podívám se na všechny předky toho dítěte od izmu\n",
    "                    predci = d.all_parents\n",
    "                    jmena = []\n",
    "                    for i in predci: \n",
    "                        jmena.append(i.lemma)\n",
    "                    \n",
    "                    #pokud tam není -ismus, tak je to špatně\n",
    "                    if rodic not in jmena: #pokud má to dítě dva rodiče - masochista má jak masochizmus a masochismus\n",
    "                        nespojeno.append((lexeme.lemma, d.lemma, rodic))\n",
    "                \n",
    "\n",
    "tisk(seznam, nespojeno)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca999ee",
   "metadata": {},
   "source": [
    "test 18: gothajský/gotajský a ethiopský a etiopský"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9489e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lezeme_nahoru(dite, hledany): #podívám se, jestli nejsou nějak propojené\n",
    "    rodice = dite.all_parents\n",
    "    if not rodice:\n",
    "        return False  # nedošli jsme k hledanému\n",
    "    if hledany in rodice:\n",
    "        return True  # hledaný je přímo rodičem\n",
    "    for r in rodice:\n",
    "        if lezeme_nahoru(r, hledany):  # rekurzivně jdeme dál\n",
    "            return True\n",
    "    return False  # pokud jsme ho nikdy nenašli\n",
    "\n",
    "#chci zjistit, jestli jsou ta slova k sobě nějak navázaná, i když ne napřimo\n",
    "def jsou_pribuzni(bez_h, h):\n",
    "    otec_h = lexicon.get_lexemes(h)[0]\n",
    "    rodice_h = otec_h.all_parents\n",
    "    otec_bez = lexicon.get_lexemes(bez_h)[0]\n",
    "    rodice_bez_h = otec_bez.all_parents\n",
    "\n",
    "    #jestli je gotaj otcem gothaje\n",
    "    if any(parent.lemma == bez_h for parent in rodice_h):\n",
    "        return 0\n",
    "    #jestli je gothaj otcem gotaje\n",
    "    elif any(parent.lemma == h for parent in rodice_bez_h):\n",
    "        return 1\n",
    "    else:\n",
    "        #pokud to není ani jedno, tak se podíváme, jestli nejsou příbuzní oklikou\n",
    "        #je gotaj nějak dítětem gothaje?\n",
    "        etiopie = lezeme_nahoru(otec_bez, otec_h)\n",
    "        #je gothaj nějak dítětem gotaje?\n",
    "        gothaj = lezeme_nahoru(otec_h, otec_bez)\n",
    "\n",
    "        if etiopie or gothaj:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "        \n",
    "def pomery(celkove, h, bez_h, vzdalene, vubec, dohromady):\n",
    "    seznam = { \"h\": h/celkove*100, \"bez_h\" : bez_h/celkove*100, \"vubec\" : vubec/celkove*100,  \"vzdalene\" : vzdalene/celkove*100}\n",
    "    vypis = {\"h\" : \"rodičem v tomto vztahu je slovo obsahující 'h' navíc\", \"bez_h\":\"rodičem v tom vztahu je slovo neobsahující zkoumané 'h'\", \n",
    "             \"vubec\": \"tato dvojice slov není nijak příbuzná\", \"vzdalene\": \"tato dvojice slov je příbuzná, ale ne napřímo\"}\n",
    "\n",
    "    #chci nejdriv vypsat všechny četnosti a poté je vypsat jejich pořadí  \n",
    "    with open(\"test18.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"S JAKOU ČETNOSTÍ SE V DERINETU NACHÁZÍ SPOJENÍ SLOV, KTERÉ SE LIŠÍM JEDNÍM H \\n\")\n",
    "        f.write(\"TABULKA ČETNOSTÍ OD NEJČASTĚJŠÍHO VZTAHU DO NEJMÉNĚ ČASTÉHO: \\n\")\n",
    "        sortovano = sorted(seznam.items(), key=lambda x: x[1], reverse=True)\n",
    "        f.write(f\"{'TYP VZTAHU'.ljust(70)}{'ČETNOST V PROCENTECH'.ljust(30)}\\n\")\n",
    "        for k, v in sortovano:\n",
    "            f.write(f\"{vypis[k].ljust(70)}{str(v).ljust(30)} \\n\")\n",
    "\n",
    "        for k, v in sortovano: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "            f.write(\"\\n\")\n",
    "            f.write(f\"{vypis[k].upper()} \\n\")\n",
    "            if k == \"h\" or k == \"bez_h\":\n",
    "                f.write(f\"  {'OTEC'.ljust(20)}{'SYN'.ljust(20)}\\n\")\n",
    "            seznamik = dohromady[k]\n",
    "            for i in sorted(seznamik, key=lambda x: x[0]):\n",
    "                f.write(f\"      {i[0].ljust(20)}{i[1].ljust(20)}\\n\")\n",
    "\n",
    "celkove = 0\n",
    "\n",
    "#jestli je jeden z nich otcem druhého, jestli jsou nějak příbuzní a jestli nejsou vůbec příbuzní\n",
    "h_ne, h_ano, vzdalene, vubec = 0, 0, 0, 0 \n",
    "h_ne_seznam, h_ano_seznam, vzdalene_seznam, vubec_seznam = set(), set(), set(), set()\n",
    "\n",
    "for lexeme in lexicon.iter_lexemes():\n",
    "    if \"h\" in lexeme.lemma and not lexeme.lemma.startswith(\"-\"):\n",
    "\n",
    "        #poodstraňuju všechna h, která se v tom slově nachází\n",
    "        indexiky = []\n",
    "        for i in range(len(lexeme.lemma)):\n",
    "            if lexeme.lemma[i] == \"h\":\n",
    "                indexiky.append(i)\n",
    "\n",
    "        novotvary = []\n",
    "        for j in indexiky:\n",
    "            novotvary.append(lexeme.lemma[:j] + lexeme.lemma[j+1:])\n",
    "\n",
    "        for k in novotvary:\n",
    "            if k in all_lemmas:\n",
    "                #print(k)\n",
    "                stav = jsou_pribuzni(k, lexeme.lemma)\n",
    "                celkove += 1\n",
    "\n",
    "                if stav == 0: #znamená to, že etiopský je rodičem ethiopský\n",
    "                    h_ano += 1\n",
    "                    h_ano_seznam.add((k, lexeme.lemma))\n",
    "                elif stav == 1: #gothaj je rodičem gotaj\n",
    "                    h_ne += 1 \n",
    "                    #je to vždycky (rodič, syn)\n",
    "                    h_ne_seznam.add((lexeme.lemma, k))\n",
    "                elif stav == 2:\n",
    "                    vzdalene += 1\n",
    "                    vzdalene_seznam.add((lexeme.lemma, k))\n",
    "                else:\n",
    "                    vubec += 1\n",
    "                    vubec_seznam.add((lexeme.lemma, k))\n",
    "\n",
    "dohromady = {\"h\": h_ano_seznam, \"bez_h\" : h_ne_seznam, \"vubec\" : vubec_seznam,  \"vzdalene\" : vzdalene_seznam}\n",
    "pomery(celkove, h_ano, h_ne, vzdalene, vubec, dohromady)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc7178",
   "metadata": {},
   "source": [
    "test 19: jeden rodič, ale rozdíl mezi velikostí rodiče a dítěte je veliká "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29aa10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tady dohledáváme slova, která by se tam měla nacházet, ale nenachází se tam \n",
    "\n",
    "with open(\"test19.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if len(lexeme.lemma) >= 10 and len(lexeme.all_parents) == 1 and len(lexeme.parent.lemma) <= 5:\n",
    "            if not lexeme.lemma.endswith((\"ovský\", \"owský\", \"ovat\", \"ový\", \"vitý\")):\n",
    "                rodic = lexeme.parent.lemma\n",
    "                index = lexeme.lemma.find(rodic)\n",
    "                if index != -1:\n",
    "                    retezec = lexeme.lemma[:index]\n",
    "                    if retezec in all_lemmas:\n",
    "                        #seradit to podle delky retezce\n",
    "                        f.write(f\"{lexeme.lemma}, {lexeme.parent.lemma}, CHYBÍ {retezec} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177fb71",
   "metadata": {},
   "source": [
    "test 20: prefixy a hranice slov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a5831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-acid-\n",
      "-aden-\n",
      "-aer-\n",
      "-aero-\n",
      "-agog-\n",
      "-agora-\n",
      "-agro-\n",
      "-aichm-\n",
      "-al-\n",
      "-alg-\n",
      "-ana-\n",
      "-andr-\n",
      "-angi-\n",
      "-angl-\n",
      "-anter-\n",
      "-anthrop-\n",
      "-antrop-\n",
      "-arachn-\n",
      "-arch-\n",
      "-arche-\n",
      "-arci-\n",
      "-arist-\n",
      "-astr-\n",
      "-audi-\n",
      "-aut-\n",
      "-balne-\n",
      "-bi-\n",
      "-bio-\n",
      "-blank-\n",
      "-blast-\n",
      "-brady-\n",
      "-bronch-\n",
      "-byr-\n",
      "-ceci-\n",
      "-centr-\n",
      "-cephalo-.-kephalo-\n",
      "-cervik-\n",
      "-chol-\n",
      "-chondr-\n",
      "-chord-\n",
      "-chron-\n",
      "-circum-\n",
      "-coel-\n",
      "-cyan-\n",
      "-cykl-\n",
      "-cyklo-\n",
      "-cyt-\n",
      "-daktyl-\n",
      "-dein-\n",
      "-dem-\n",
      "-dendr-\n",
      "-dermat-\n",
      "-di-\n",
      "-dia-\n",
      "-doch-\n",
      "-dol-\n",
      "-dys-\n",
      "-e-\n",
      "-ek-\n",
      "-eko-\n",
      "-ekt-\n",
      "-elektr-\n",
      "-en-\n",
      "-enanti-\n",
      "-end-\n",
      "-ent-\n",
      "-enter-\n",
      "-ereuth-\n",
      "-erg-\n",
      "-etho-\n",
      "-ethyl-\n",
      "-etn-\n",
      "-etno-\n",
      "-eur-\n",
      "-euro-\n",
      "-ex-\n",
      "-exo-\n",
      "-fac-\n",
      "-fag-\n",
      "-felin-\n",
      "-ferr-\n",
      "-fid-\n",
      "-fil-\n",
      "-flori-\n",
      "-fob-\n",
      "-fon-\n",
      "-fot-\n",
      "-frank-\n",
      "-free-\n",
      "-fug-\n",
      "-fyt-\n",
      "-galvan-\n",
      "-gam-\n",
      "-gastr-\n",
      "-ge-\n",
      "-gen-\n",
      "-geo-\n",
      "-geront-\n",
      "-gestalt-\n",
      "-giga-\n",
      "-gnos-\n",
      "-gon-\n",
      "-graf-\n",
      "-gram-\n",
      "-granul-\n",
      "-gymn-\n",
      "-gyn-\n",
      "-hepat-\n",
      "-heter-\n",
      "-hod-\n",
      "-hol-\n",
      "-hom-\n",
      "-hydr-\n",
      "-hydroxy-\n",
      "-hygr-\n",
      "-hymen-\n",
      "-hyper-\n",
      "-hypn-\n",
      "-hypo-\n",
      "-idio-\n",
      "-infra-\n",
      "-inter-\n",
      "-intra-\n",
      "-iso-\n",
      "-kalyptr-\n",
      "-kancer-\n",
      "-karcin-\n",
      "-kardi-\n",
      "-karp-\n",
      "-kilo-\n",
      "-kinet-\n",
      "-klast-\n",
      "-klin-\n",
      "-kok-\n",
      "-kortik-\n",
      "-krat-\n",
      "-krimi-\n",
      "-kry-\n",
      "-krypt-\n",
      "-kvadr-\n",
      "-kvazi-\n",
      "-kyan-\n",
      "-lal-\n",
      "-lali-\n",
      "-laryng-\n",
      "-leuk-\n",
      "-lit-\n",
      "-lith-\n",
      "-log-\n",
      "-logh-\n",
      "-ly-\n",
      "-makr-\n",
      "-malak-\n",
      "-mamm-\n",
      "-mant-\n",
      "-math-\n",
      "-max-\n",
      "-maxi-\n",
      "-medi-\n",
      "-mega-\n",
      "-mening-\n",
      "-merit-\n",
      "-mes-\n",
      "-meta-\n",
      "-metr-\n",
      "-metro-\n",
      "-midi-\n",
      "-mikr-\n",
      "-mikro-\n",
      "-mili-\n",
      "-mim-\n",
      "-mini-\n",
      "-mon-\n",
      "-morf-\n",
      "-moto-\n",
      "-multi-\n",
      "-my-\n",
      "-myx-\n",
      "-nan-\n",
      "-nano-\n",
      "-naut-\n",
      "-nekr-\n",
      "-neo-\n",
      "-neur-\n",
      "-nitr-\n",
      "-nitro-\n",
      "-nom-\n",
      "-nomie-\n",
      "-ochl-\n",
      "-odont-\n",
      "-ofi-\n",
      "-ofthalm-\n",
      "-olig-\n",
      "-omfal-\n",
      "-onk-\n",
      "-opt-\n",
      "-orchi-\n",
      "-orth-\n",
      "-oste-\n",
      "-ot-\n",
      "-oxy-\n",
      "-paid-\n",
      "-palai-\n",
      "-paleo-\n",
      "-pali-\n",
      "-pan-\n",
      "-pant-\n",
      "-para-\n",
      "-pat-\n",
      "-path-\n",
      "-ped-\n",
      "-pen-\n",
      "-peri-\n",
      "-pes-\n",
      "-pet-\n",
      "-petr-\n",
      "-pidi-\n",
      "-pik-\n",
      "-pikto-\n",
      "-plan-\n",
      "-plo-\n",
      "-ploi-\n",
      "-plut-\n",
      "-pneu-\n",
      "-pol-\n",
      "-poli-\n",
      "-polon-\n",
      "-poly-\n",
      "-pom-\n",
      "-post-\n",
      "-prax-\n",
      "-profi-\n",
      "-prot-\n",
      "-psych-\n",
      "-pyr-\n",
      "-pás-\n",
      "-radi-\n",
      "-retr-\n",
      "-rhynch-\n",
      "-scinti-\n",
      "-sem-\n",
      "-semi-\n",
      "-semit-\n",
      "-silik-\n",
      "-sin-\n",
      "-skop-\n",
      "-soci-\n",
      "-sof-\n",
      "-som-\n",
      "-somat-\n",
      "-sosi-\n",
      "-sperm-\n",
      "-spor-\n",
      "-stat-\n",
      "-stereo-\n",
      "-strept-\n",
      "-sub-\n",
      "-super-\n",
      "-surd-\n",
      "-sympat-\n",
      "-syn-\n",
      "-syring-\n",
      "-sém-\n",
      "-tachy-\n",
      "-takt-\n",
      "-techn-\n",
      "-tekt-\n",
      "-tel-\n",
      "-term-\n",
      "-tetra-\n",
      "-thek-\n",
      "-theo-\n",
      "-ther-\n",
      "-therm-\n",
      "-thi-\n",
      "-thék-\n",
      "-tim-\n",
      "-tol-\n",
      "-top-\n",
      "-trans-\n",
      "-trem-\n",
      "-tri-\n",
      "-trib-\n",
      "-troch-\n",
      "-tromb-\n",
      "-trop-\n",
      "-turb-\n",
      "-typ-\n",
      "-téka-\n",
      "-ultra-\n",
      "-ur-\n",
      "-video-\n",
      "-vitelo-\n",
      "-ware-\n",
      "-wiki-\n",
      "-zo-\n"
     ]
    }
   ],
   "source": [
    "#dodat tam ty hranice slov\n",
    "\n",
    "def tvorba_pruniku(prvni, druhy): #prvni je kratsi\n",
    "    tabulka = [[0 for _ in range(len(druhy))] for _ in range(len(prvni))]\n",
    "    \n",
    "    for i in range(len(prvni)): #ted mam kdy jsou to stejne hodnoty\n",
    "        for j in range(len(druhy)):\n",
    "            if prvni[i] == druhy[j]:\n",
    "                tabulka[i][j] = 1\n",
    "    \n",
    "    slovicko = \"\"\n",
    "    slovo = \"\"\n",
    "    vysledek = []\n",
    "    for i in range(len(prvni)):\n",
    "        for j in range(len(druhy)):\n",
    "            slovicko = \"\"\n",
    "            while i < len(prvni) and j < len(druhy) and tabulka[i][j] == 1:\n",
    "                slovicko += prvni[i]\n",
    "                i += 1\n",
    "                j += 1\n",
    "            if len(slovo) < len(slovicko):\n",
    "                slovo = slovicko\n",
    "                vysledek = [slovicko]\n",
    "            elif len(slovo) == len(slovicko):\n",
    "                vysledek.append(slovicko)\n",
    "\n",
    "    return vysledek\n",
    "    \n",
    "\n",
    "def hledani_pruniku(seznam):\n",
    "    prubezny = [seznam[0]]\n",
    "    for i in range(len(seznam)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else: \n",
    "            pomocnik = []\n",
    "            for j in prubezny:\n",
    "                pomocnik.extend(tvorba_pruniku(j, seznam[i]))\n",
    "            prubezny = pomocnik    \n",
    "\n",
    "    return sorted(prubezny, key=len, reverse=True)\n",
    "\n",
    "def deti(f, deticky, podstring):\n",
    "    mozne_deti = []\n",
    "    for i in all_lemmas:\n",
    "        if podstring in i and i not in deticky:\n",
    "            mozne_deti.append(i)\n",
    "\n",
    "    f.write(f\"{lexeme.lemma}\\n\")\n",
    "    for i in mozne_deti:\n",
    "        f.write(f\"      {i}\\n\")\n",
    "\n",
    "with open(\"test20.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if lexeme.pos == \"Affixoid\" or lexeme.pos == \"NeoCon\":\n",
    "            deticky = []\n",
    "            print(lexeme.lemma)\n",
    "            for i in lexeme.children:\n",
    "                deticky.append(i.lemma)\n",
    "\n",
    "            if deticky == [] :\n",
    "                aff = lexeme.lemma[1:-1]\n",
    "                deti(f, deticky,aff)\n",
    "            \n",
    "            elif len(deticky) == 1:\n",
    "                aff = lexeme.lemma[1:-1]\n",
    "                if aff in deticky[0]:\n",
    "                    deti(f, deticky, aff)\n",
    "                \n",
    "                #kdyz se bude lisit rodic a dite, tak nevím podle čeho se řídit\n",
    "\n",
    "            else: \n",
    "                #tuhle prisernou funkci pisu kvuli tomu, že název affixoidu neodpovídá tomu, co se nachází ve slovech\n",
    "                podstringy = hledani_pruniku(deticky)\n",
    "                podstring = podstringy[0]\n",
    "\n",
    "                deti(f, deticky, podstring)           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5661489",
   "metadata": {},
   "source": [
    "test 21: Hubbert a Hubert a podobné "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test21.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    #tady najdu to, kdyz se ta pismena budou opakovat\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if any(lexeme.lemma[i] == lexeme.lemma[i + 1] for i in range(len(lexeme.lemma) - 1)):\n",
    "            #musim najit ten index\n",
    "            for i in range(lexeme.lemma) - 1:\n",
    "                if lexeme.lemma[i] == lexeme.lemma[i + 1]:\n",
    "                    nove = lexeme.lemma[:i] + lexeme.lemma[i+1:]\n",
    "                    if nove in all_lemmas:\n",
    "                        #potom uz je to znovu h a bez h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737adbff",
   "metadata": {},
   "source": [
    "test 22: pesimismus a pesimizmus, ale něco jako autizta a austista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test22.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if \"z\" in lexeme.lemma: #v korpusech se častěji nachází s než z\n",
    "            for i in range(len(lexeme.lemma)):\n",
    "                if lexeme.lemma[i] == \"z\":\n",
    "                    nove = lexeme.lemma[:i] + \"z\" + lexeme.lemma[i+1:]\n",
    "                    if nove in all_lemmas: \n",
    "                        # tak znovu h a bez h\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8b4cb",
   "metadata": {},
   "source": [
    "test 23: acyl -> vezmu všechno s acylem, vezmu jeho další části a poté se podívám v jakých dalších slovech se nacházejí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0771fd7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lexeme \u001b[38;5;129;01min\u001b[39;00m lexicon.iter_lexemes():\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33macyl\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m lexeme.lemma \u001b[38;5;129;01mand\u001b[39;00m lexeme.feats[\u001b[33m'\u001b[39m\u001b[33mLoanword\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m lexeme.lemma != \u001b[33m\"\u001b[39m\u001b[33macyl\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m        \u001b[43mhledani_podslov\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43macyl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvidene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mhledani_podslov\u001b[39m\u001b[34m(slovo, videne, f)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m celkove:\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m videne:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         \u001b[43mhledani_podslov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvidene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mhledani_podslov\u001b[39m\u001b[34m(slovo, videne, f)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhledani_podslov\u001b[39m(slovo, videne, f):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     index = \u001b[43mlexeme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslovo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     pred, po = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m     vsechno_po, vsechno_pred = \u001b[38;5;28mset\u001b[39m(), \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mValueError\u001b[39m: substring not found"
     ]
    }
   ],
   "source": [
    "def hledani_podslov(slovo, uvnitr, videne, f):\n",
    "    index = slovo.index(uvnitr)\n",
    "    pred, po = \"\", \"\"\n",
    "    vsechno_po, vsechno_pred = set(), set()\n",
    "    if index != 0:\n",
    "        pred = lexeme.lemma[:index]\n",
    "    po = lexeme.lemma[index + len(slovo):]\n",
    "\n",
    "    if pred != \"\" and pred not in videne:\n",
    "        vsechno_pred = {lemma for lemma in all_lemmas if pred in lemma}\n",
    "        videne.add(pred)\n",
    "    if po not in videne:\n",
    "        vsechno_po = {lemma for lemma in all_lemmas if pred in lemma}\n",
    "        videne.add(po)\n",
    "\n",
    "    celkove = vsechno_po | vsechno_pred\n",
    "\n",
    "    for i in celkove:\n",
    "        slova = lexicon.get_lexemes(i)\n",
    "        if slova == []:\n",
    "            continue\n",
    "        else:\n",
    "            slovo = slova[0]\n",
    "            rodice = slovo.all_parents\n",
    "            if i not in rodice:\n",
    "                f.write(f\"{pred}, {slovo}  \\n\")\n",
    "    \n",
    "    for i in celkove:\n",
    "        if i not in videne:\n",
    "            hledani_podslov(i, videne, f)\n",
    "\n",
    "\n",
    "with open(\"test23.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    videne = set()\n",
    "    seznam = []\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if \"acyl\" in lexeme.lemma and lexeme.feats['Loanword'] and lexeme.lemma != \"acyl\":\n",
    "           seznam.append(lexeme.lemma)\n",
    "        \n",
    "    for i in seznam:\n",
    "        hledani_podslov(\"acyl\", videne, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304a9c5",
   "metadata": {},
   "source": [
    "test 24: Bukowský, bukovský a celkově tohle to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "41c604bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test24.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if lexeme.lemma.endswith(\"owský\"):\n",
    "                rodice = []\n",
    "                for i in lexeme.all_parents:\n",
    "                    rodice.append(i.lemma)\n",
    "            \n",
    "                nove = lexeme.lemma[:-4] + \"v\" + lexeme.lemma[-3:]\n",
    "                if \"w\" in nove:\n",
    "                    index = nove.index(\"w\")\n",
    "                    lepsi = nove[:index] + \"v\" + nove[index + 1:]\n",
    "                    if lepsi in all_lemmas and lepsi not in rodice:\n",
    "                        f.write(f\"{lexeme.lemma}, {lepsi} \\n\")\n",
    "                    elif lepsi.lower() in all_lemmas and lepsi.lower() not in rodice:\n",
    "                        f.write(f\"{lexeme.lemma}, {lepsi.lower} \\n\")\n",
    "\n",
    "                else:\n",
    "                    if nove in all_lemmas and nove not in rodice:\n",
    "                        f.write(f\"{lexeme.lemma}, {nove} \\n\")\n",
    "                    elif nove.lower() in all_lemmas and nove.lower() not in rodice:\n",
    "                        f.write(f\"{lexeme.lemma}, {nove.lower()} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272bf8f8",
   "metadata": {},
   "source": [
    "test 25: fake affixoidy\n",
    "\n",
    "u nějakých affixoidů a neoconů jsou připojena slova, která by tam podle mě vůbec neměla být \n",
    "příklad: -takt- -> architekt nebo -pneu- ->  tachypnoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e942c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"fake_affixoid.txt\", \"w\", encoding=\"utf-8\") as f: #kdyz tam dodam with, tak se mi to samo zavre\n",
    "    for lexeme in lexicon.iter_lexemes():\n",
    "        if (lexeme.pos == \"Affixoid\" or lexeme.pos == \"NeoCon\"):  #and len(lexeme.lemma) > 4:\n",
    "            # je to 4, protoze -my- jeste obsahuje ty dve pomlcky\n",
    "            #kdyz to bude delsi nez dva, zbavim se tech casti slov jako jsou -my- -e-\n",
    "            slovo = lexeme.lemma[1:-1] #tak bych se mela zbavit tech pomlcek\n",
    "\n",
    "            for lem in lexeme.children:\n",
    "                if slovo not in lem.lemma or not lem.lemma.startswith(slovo):\n",
    "                    f.write(f\"{lem.lemma}, {slovo} \\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-dir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
